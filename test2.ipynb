{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from make_taxonomy_rdrs import *\n",
    "from get_ner_from_query2 import *\n",
    "from datasets.process_rdrs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinc_entities_dict = get_distinc_entity_dict(\"datasets/rdrs/rdrs\")\n",
    "# tag_topic_freq = {\"Medication\":{}, \"Disease\":{}, \"ADR\":{}}\n",
    "\n",
    "# with open(\"retrived_topics/rdrs/rdrs_entity_topics_dict.json\", \"r\", encoding=\"utf-8\") as reader:\n",
    "#     data = json.load(reader)\n",
    "#     for entity, topics in data.items():\n",
    "#         for topic, id_topic in topics.items():\n",
    "#             ent_tag_freq_dict = distinc_entities_dict[entity] # distinc_entities_dict == {entity : {tag1:freq, tag2:freq, ...}}\n",
    "#             topic = f\"{topic} | {id_topic}\"\n",
    "#             for tag, freq in ent_tag_freq_dict.items():\n",
    "#                 if topic not in tag_topic_freq[tag]:\n",
    "#                     tag_topic_freq[tag][topic] = freq\n",
    "#                 else:\n",
    "#                     tag_topic_freq[tag][topic] += freq\n",
    "#         #print(tag_topic_freq)\n",
    "\n",
    "# for tag, topics in tag_topic_freq.items():\n",
    "#     topics = dict(sorted(topics.items(), key=lambda x: x[1], reverse=True))\n",
    "#     write_to_file(f\"retrived_topics/rdrs/{tag}_topic_freq.txt\", topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_tag_topic_entity_dict(taxonomy_file, LIMIT, LANG, rdrs_topic_entity_dict):\n",
    "    filename_with_extension = os.path.basename(taxonomy_file)\n",
    "    tag_name = os.path.splitext(filename_with_extension)[0]\n",
    "    itemLabel_set = {}\n",
    "    taxonomy_ids = []\n",
    "    with open(taxonomy_file, \"r\", encoding=\"utf-8\") as reader:\n",
    "        lines = reader.readlines()\n",
    "        for line in lines:\n",
    "            tax_id = line.split()[-1]\n",
    "            taxonomy_ids.append(tax_id)\n",
    "\n",
    "\n",
    "    for tax_id in tqdm(taxonomy_ids, desc=f\"Creating gzt for {tag_name}\"):\n",
    "        current_limit = LIMIT\n",
    "        results = {}\n",
    "        while current_limit > 0:\n",
    "            try:\n",
    "                results = get_results(endpoint_url, current_limit, tax_id, LANG)\n",
    "                break  # If successful, break out of the while loop\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching results with limit {current_limit}: {e}\")\n",
    "                if current_limit <= 500000:\n",
    "                    current_limit -= 10000  # Decrease limit by 10,000 and retry\n",
    "                else:\n",
    "                    current_limit /= 2\n",
    "                if current_limit <= 0:\n",
    "                    print(f\"Failed to fetch results for tax_id {tax_id} after several attempts.\")\n",
    "                    continue  # Skip to the next tax_id if limit becomes zero or negative\n",
    "        \n",
    "        if len(results) > 0:\n",
    "            for result in results[\"results\"][\"bindings\"]:\n",
    "                itemLabel = result['itemLabel']['value'].lower()\n",
    "                if tax_id not in rdrs_topic_entity_dict:\n",
    "                    rdrs_topic_entity_dict[tax_id] = [itemLabel]\n",
    "                else:\n",
    "                    rdrs_topic_entity_dict[tax_id].append(itemLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxonomy_directory = 'label_taxonomy/rdrs/'  # Specify the directory path\n",
    "# LIMIT = 1000000\n",
    "# LANG = \"ru\"\n",
    "\n",
    "# for filename in os.listdir(taxonomy_directory):\n",
    "#     if filename.endswith(\".txt\"):\n",
    "#         tag_name = os.path.splitext(filename)[0]\n",
    "#         tag_topic_entity_dict = {}\n",
    "#         filepath = os.path.join(taxonomy_directory, filename)\n",
    "#         print(f\"Processing {filepath}\")\n",
    "#         add_to_tag_topic_entity_dict(filepath, LIMIT, LANG, tag_topic_entity_dict)\n",
    "#         write_to_file(f\"rdrs_{tag_name}_entity_dict.json\", tag_topic_entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_from_file(file_path):\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "#     return data\n",
    "\n",
    "# def write_list_of_words_to_file_txt(filepath, mylist):\n",
    "#     with open(filepath, \"w\", encoding=\"utf-8\") as writer:\n",
    "#         for word in mylist:\n",
    "#             writer.write(f\"{word}\\n\")\n",
    "\n",
    "# fold = \"rdrs5\"\n",
    "# train_file = f\"datasets/rdrs/{fold}\"\n",
    "# retrived_topic_dict = read_from_file(\"retrived_topics/rdrs/rdrs_entity_topics_dict.json\")\n",
    "# ADR_topic_dict = read_from_file(\"label_taxonomy/rdrs/rdrs_ADR_entity_dict.json\")\n",
    "# Medication_topic_dict = read_from_file(\"label_taxonomy/rdrs/rdrs_Medication_entity_dict.json\")\n",
    "# Disease_topic_dict = read_from_file(\"label_taxonomy/rdrs/rdrs_Disease_entity_dict.json\")\n",
    "\n",
    "# ADR_entity_list = set()\n",
    "# Medication_entity_list = set()\n",
    "# Disease_entity_list = set()\n",
    "\n",
    "# distinc_entity_dict = get_distinc_entity_dict(train_file)\n",
    "# topic_dict_train_file = set()\n",
    "# for entity in distinc_entity_dict:\n",
    "#     topic_dict = retrived_topic_dict[entity]\n",
    "#     for topic, id in topic_dict.items():\n",
    "#         topic_dict_train_file.add(id)\n",
    "# for id in topic_dict_train_file:\n",
    "#     if id in ADR_topic_dict:\n",
    "#         for entity in ADR_topic_dict[id]:\n",
    "#             ADR_entity_list.add(entity)\n",
    "#     if id in Medication_topic_dict:\n",
    "#         for entity in Medication_topic_dict[id]:\n",
    "#             Medication_entity_list.add(entity)\n",
    "#     if id in Disease_topic_dict:\n",
    "#         for entity in Disease_topic_dict[id]:\n",
    "#             Disease_entity_list.add(entity)\n",
    "\n",
    "# os.makedirs(f\"gazetteers/gzt_{fold}/\", exist_ok=True)\n",
    "# write_list_of_words_to_file_txt(f\"gazetteers/gzt_{fold}/ADR.txt\", ADR_entity_list)\n",
    "# write_list_of_words_to_file_txt(f\"gazetteers/gzt_{fold}/Medication.txt\", Medication_entity_list)\n",
    "# write_list_of_words_to_file_txt(f\"gazetteers/gzt_{fold}/Disease.txt\", Disease_entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rdrs5_valid.txt: 100%|██████████| 327/327 [00:05<00:00, 55.83it/s]\n"
     ]
    }
   ],
   "source": [
    "fold = 5\n",
    "freq_labels = {}\n",
    "\n",
    "process_data(f\"/home/andrew6072/Downloads/dataset/RDRS-main/data/interim/{fold}/valid.json\", f\"rdrs{fold}_valid.txt\", freq_labels)\n",
    "with open(f\"datasets/rdrs/rdrs{fold}_valid_freq.txt\", 'w', encoding='utf-8') as writer:\n",
    "    for label, freq in freq_labels.items():\n",
    "        writer.write(f\"{label} {freq}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
